{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4b5da1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from src.inference import predict_emotion_on_image, load_class_map\n",
    "from src.evaluate import plot_confusion_matrix, print_classification_report\n",
    "import json, os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d275e7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Single image demo — prints result and shows bounding box if any\n",
    "IMG_PATH = \"examples/face1.png\"   # change to any example image you have\n",
    "MODEL_PATH = \"models/emotion_recognition_model.h5\"\n",
    "CLASSMAP_PATH = \"models/class_indices.json\"\n",
    "\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print(\"Model not found at\", MODEL_PATH, \" — put your trained .h5 there or run the training cell.\")\n",
    "else:\n",
    "    results = predict_emotion_on_image(IMG_PATH, model_path=MODEL_PATH, classmap_path=CLASSMAP_PATH, show=True)\n",
    "    if not results:\n",
    "        print(\"No faces detected in image.\")\n",
    "    else:\n",
    "        for r in results:\n",
    "            print(f\"{r['label']} ({r['confidence']*100:.2f}%)  box={r['box']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4e4f55",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from src.dataset import create_generators\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "VALID_DIR = \"dataset/train\"   # flow_from_directory with subset=\"validation\" will be used\n",
    "IMG_SIZE = (224,224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    # use same generator logic to get validation generator\n",
    "    train_gen, val_gen = create_generators(VALID_DIR, img_size=IMG_SIZE, batch_size=BATCH_SIZE)\n",
    "    model = load_model(MODEL_PATH)\n",
    "\n",
    "    # Predict on entire validation set (may take time)\n",
    "    val_steps = val_gen.samples // val_gen.batch_size + (1 if val_gen.samples % val_gen.batch_size != 0 else 0)\n",
    "    preds = model.predict(val_gen, steps=val_steps, verbose=1)\n",
    "    y_true = val_gen.classes  # ground-truth labels (integers)\n",
    "    y_pred = np.argmax(preds, axis=1)\n",
    "\n",
    "    labels = [k for k, v in sorted(val_gen.class_indices.items(), key=lambda item: item[1])]\n",
    "    print(\"Labels:\", labels)\n",
    "\n",
    "    # Save confusion matrix plot\n",
    "    plot_confusion_matrix(y_true, y_pred, labels, out_path=\"docs/confusion_matrix.png\")\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(\"docs/confusion_matrix.png\"))\n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "    print_classification_report(y_true, y_pred, labels)\n",
    "else:\n",
    "    print(\"Model not found — run training first or copy weights to models/emotion_recognition_model.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
